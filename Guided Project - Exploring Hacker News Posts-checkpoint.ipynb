{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacker News guided project\n",
    "\n",
    "In this project, we'll work with a dataset of submissions to popular technology site Hacker News."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") receive votes and comments, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "You can find the data set here, but note that we have reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that didn't receive any comments and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "- **id:** the unique identifier from Hacker News for the post\n",
    "- **title:** the title of the post\n",
    "- **url:** the URL that the posts links to, if the post has a URL\n",
    "- **num_points:** the number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- **num_comments:** the number of comments on the post\n",
    "- **author:** the username of the person who submitted the post\n",
    "- **created_at:** the date and time of the post's submission\n",
    "    \n",
    "**We're specifically interested in posts with titles that begin with either Ask HN or Show HN. Users submit Ask HN posts to ask the Hacker News community a specific question.**\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    "**Do Ask HN or Show HN receive more comments on average?**\n",
    "\n",
    "**Do posts created at a certain time receive more comments on average?**\n",
    "\n",
    "Let's start by importing the libraries we need and reading the dataset into a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new class which makes it possible to format text in colour or bold etc.\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "opened_file = open('hacker_news.csv',encoding = 'utf8')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "# hn = pd.read_csv('CSV FILES/hacker_news.csv')\n",
    "\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "print('')\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and Clean data\n",
    "\n",
    "Now that all the data has been imported and the header has been split from the actual data its time for the next stap in this project. First the data will be checked on missing data. After the checks have been performed the data will be filtered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column \u001b[1mid \u001b[0mhas \u001b[93m\u001b[1m0 \u001b[0mmissing values\n",
      "Column \u001b[1mtitle \u001b[0mhas \u001b[93m\u001b[1m0 \u001b[0mmissing values\n",
      "Column \u001b[1murl \u001b[0mhas \u001b[93m\u001b[1m13863 \u001b[0mmissing values\n",
      "Column \u001b[1mnum_points \u001b[0mhas \u001b[93m\u001b[1m0 \u001b[0mmissing values\n",
      "Column \u001b[1mnum_comments \u001b[0mhas \u001b[93m\u001b[1m0 \u001b[0mmissing values\n",
      "Column \u001b[1mauthor \u001b[0mhas \u001b[93m\u001b[1m0 \u001b[0mmissing values\n",
      "Column \u001b[1mcreated_at \u001b[0mhas \u001b[93m\u001b[1m0 \u001b[0mmissing values\n"
     ]
    }
   ],
   "source": [
    "# Define a function to search for null data in the given dataset\n",
    "def check_null_data(dataset_header, dataset):\n",
    "    \n",
    "    total_missing = []\n",
    "    columns = len(dataset_header)\n",
    "    \n",
    "    # Loop over each row in the dataset to identify any missing values at the given index\n",
    "    for column in range(columns):\n",
    "    \n",
    "        null_value = False \n",
    "        null_count = 0\n",
    "    \n",
    "        for row in dataset:\n",
    "            if row[column] == '':\n",
    "                null_value = True\n",
    "                null_count += 1\n",
    "            if null_value == True:\n",
    "                #print(a)\n",
    "                #print(dataset_header,'\\n')\n",
    "                #print('Row Index: ', dataset.index(row),'\\n') # Print the row number where the error was found\n",
    "                #print(row, '\\n')\n",
    "                null_value = False\n",
    "        \n",
    "        total_missing.append([dataset_header[column],null_count])\n",
    "        \n",
    "    # Print the number of missing values identified at the given index\n",
    "    template = \"Column \" + color.BOLD + \"{} \" + color.END + \"has \" + color.YELLOW + color.BOLD + \"{} \" + color.END + \"missing values\"\n",
    "    \n",
    "    for col, missing in total_missing:    \n",
    "        print(template.format(col, missing))\n",
    "    \n",
    "#run the defined function    \n",
    "check_null_data(headers, hn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, there are a lot of missing values in the column **'url'**. All other columns show no missing values.Since the information about URL is not deemed necessary we can continue with filtering the data. As mentioned before we are especially interested in 'ask posts' and 'show posts'. The next step will be to split the dataset in three lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are\u001b[93m\u001b[1m 9,139 \u001b[0mof \u001b[1m'ask posts'\u001b[0m in the dataset  \n",
      "\n",
      "There are\u001b[93m\u001b[1m 10,158 \u001b[0mof \u001b[1m'show posts'\u001b[0m in the dataset  \n",
      "\n",
      "There are\u001b[93m\u001b[1m 273,822 \u001b[0mof \u001b[1m'other posts'\u001b[0m in the dataset \n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "for row in hn:\n",
    "    title = row[1].lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "#show how many posts there are of each type \n",
    "\n",
    "template = \"There are\" + color.YELLOW + color.BOLD + \" {:,} \" + color.END +  \"of {} in the dataset \"\n",
    "        \n",
    "print(template.format(len(ask_posts),color.BOLD + \"'ask posts'\" + color.END),'\\n')\n",
    "print(template.format(len(show_posts),color.BOLD + \"'show posts'\" + color.END),'\\n')\n",
    "print(template.format(len(other_posts),color.BOLD + \"'other posts'\" + color.END))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average comments on \u001b[1mask posts\u001b[0m are: \u001b[1m\u001b[93m10.393478498741656\u001b[0m \n",
      "\n",
      "Average comments on \u001b[1mshow post\u001b[0m are: \u001b[1m\u001b[93m4.886099625910612\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    \n",
    "    ask_comment = int(row[4])\n",
    "    total_ask_comments += ask_comment\n",
    "    \n",
    "avg_ask_comments = total_ask_comments/len(ask_posts)\n",
    "\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    \n",
    "    show_comment = int(row[4])\n",
    "    total_show_comments += show_comment\n",
    "    \n",
    "avg_show_comments = total_show_comments/len(show_posts)\n",
    "\n",
    "template = \"Average comments on {} are: \"+ color.BOLD + color.YELLOW + \"{}\" + color.END\n",
    "\n",
    "#calc avg ask comments\n",
    "\n",
    "print(template.format(color.BOLD + \"ask posts\" + color.END,avg_ask_comments),'\\n')\n",
    "\n",
    "#calc avg show comments\n",
    "print(template.format(color.BOLD + \"show post\" + color.END, avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calculating the average amount of comments per post for both ask posts as well as show post it can be concluded that ask posts receive more comments on average.\n",
    "\n",
    "The second question that needs to be answered is: Do posts created at a certain time receive more comments on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing datetime library\n",
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6],int(row[4])])#appending created at and number of comments\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    \n",
    "    comments_count = row[1]\n",
    "    date_string = row[0]\n",
    "    \n",
    "    date_created = dt.datetime.strptime(date_string,\"%m/%d/%Y %H:%M\")\n",
    "    \n",
    "    hour_created = date_created.hour\n",
    "    \n",
    "    if hour_created not in counts_by_hour:\n",
    "        \n",
    "        counts_by_hour[hour_created] = 1\n",
    "        comments_by_hour[hour_created] = comments_count \n",
    "    else:\n",
    "        counts_by_hour[hour_created] += 1\n",
    "        comments_by_hour[hour_created] += comments_count\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPosts created\u001b[0m by hour:  {2: 269, 1: 282, 22: 383, 21: 518, 19: 552, 17: 587, 15: 646, 14: 513, 13: 444, 11: 312, 10: 282, 9: 222, 7: 226, 3: 271, 23: 343, 20: 510, 16: 579, 8: 257, 0: 301, 18: 614, 12: 342, 4: 243, 6: 234, 5: 209} \n",
      "\n",
      "\u001b[1mTotal comments added\u001b[0m by hour: {2: 2996, 1: 2089, 22: 3372, 21: 4500, 19: 3954, 17: 5547, 15: 18525, 14: 4972, 13: 7245, 11: 2797, 10: 3013, 9: 1477, 7: 1585, 3: 2154, 23: 2297, 20: 4462, 16: 4466, 8: 2362, 0: 2277, 18: 4877, 12: 4234, 4: 2360, 6: 1587, 5: 1838}\n"
     ]
    }
   ],
   "source": [
    "print(color.BOLD + 'Posts created' + color.END, 'by hour: ', counts_by_hour,'\\n')\n",
    "\n",
    "print(color.BOLD + 'Total comments added' + color.END, 'by hour:', comments_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for key in counts_by_hour:\n",
    "    avg_posts = comments_by_hour[key]/counts_by_hour[key]\n",
    "    avg_by_hour.append([key,avg_posts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11.137546468401487, 2],\n",
       " [7.407801418439717, 1],\n",
       " [8.804177545691905, 22],\n",
       " [8.687258687258687, 21],\n",
       " [7.163043478260869, 19],\n",
       " [9.449744463373083, 17],\n",
       " [28.676470588235293, 15],\n",
       " [9.692007797270955, 14],\n",
       " [16.31756756756757, 13],\n",
       " [8.96474358974359, 11],\n",
       " [10.684397163120567, 10],\n",
       " [6.653153153153153, 9],\n",
       " [7.013274336283186, 7],\n",
       " [7.948339483394834, 3],\n",
       " [6.696793002915452, 23],\n",
       " [8.749019607843136, 20],\n",
       " [7.713298791018998, 16],\n",
       " [9.190661478599221, 8],\n",
       " [7.5647840531561465, 0],\n",
       " [7.94299674267101, 18],\n",
       " [12.380116959064328, 12],\n",
       " [9.7119341563786, 4],\n",
       " [6.782051282051282, 6],\n",
       " [8.794258373205741, 5]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's swap the column order from avg_by_hour\n",
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "    \n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTop 5 Hours for Ask Posts Comments\u001b[0m \n",
      "\n",
      "At 17:00: Posts recieve on average 28.68 comments per post\n",
      "At 15:00: Posts recieve on average 16.32 comments per post\n",
      "At 14:00: Posts recieve on average 12.38 comments per post\n",
      "At 04:00: Posts recieve on average 11.14 comments per post\n",
      "At 12:00: Posts recieve on average 10.68 comments per post\n"
     ]
    }
   ],
   "source": [
    "#sorting swap_avg_by_hour in descending order\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "print(color.BOLD + \"Top 5 Hours for Ask Posts Comments\" + color.END,'\\n')\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    hour_formatted = dt.datetime.strptime(str(row[1]),'%H')\n",
    "    hour_formatted += dt.timedelta(hours=2) #converting EST to UTC-3  \n",
    "    hour_formatted = hour_formatted.strftime('%H:%M')\n",
    "\n",
    "    print('At {}: Posts recieve on average {:.2f} comments per post'.format(hour_formatted,row[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that at certain hours posts tend to receive more comments. The end of the afternoon and beginning of the evening are times that a post is more likely to receive a lot of comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
